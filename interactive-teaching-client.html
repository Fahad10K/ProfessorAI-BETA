<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prof_AI - Interactive Teaching Mode</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 1000px;
            width: 100%;
            padding: 40px;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 10px;
            font-size: 2.2em;
        }

        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 1em;
        }

        .status-card {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 20px;
            border-left: 4px solid #667eea;
        }

        .status-row {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }

        .status-row:last-child {
            margin-bottom: 0;
        }

        .status-label {
            font-weight: 600;
            color: #555;
        }

        .status-value {
            color: #333;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }

        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
        }

        .status-indicator.connected {
            background: #10b981;
            box-shadow: 0 0 10px #10b981;
            animation: pulse 2s infinite;
        }

        .status-indicator.disconnected {
            background: #ef4444;
        }

        .status-indicator.listening {
            background: #3b82f6;
            box-shadow: 0 0 10px #3b82f6;
            animation: pulse 1s infinite;
        }

        .status-indicator.speaking {
            background: #f59e0b;
            box-shadow: 0 0 10px #f59e0b;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .course-selector {
            margin-bottom: 20px;
        }

        .course-selector label {
            display: block;
            font-weight: 600;
            margin-bottom: 10px;
            color: #333;
        }

        .course-selector select,
        .course-selector input {
            width: 100%;
            padding: 12px;
            border: 2px solid #e5e7eb;
            border-radius: 8px;
            font-size: 1em;
            background: white;
            margin-bottom: 10px;
        }

        .controls {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
        }

        button {
            flex: 1;
            padding: 15px 30px;
            border: none;
            border-radius: 10px;
            font-size: 1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .btn-start {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .btn-start:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }

        .btn-continue {
            background: #10b981;
            color: white;
        }

        .btn-continue:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(16, 185, 129, 0.4);
        }

        .btn-end {
            background: #ef4444;
            color: white;
        }

        .btn-end:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(239, 68, 68, 0.4);
        }

        .vad-indicator {
            margin-bottom: 20px;
        }

        .vad-label {
            font-weight: 600;
            color: #333;
            margin-bottom: 8px;
        }

        .vad-bar-container {
            width: 100%;
            height: 20px;
            background: #e5e7eb;
            border-radius: 10px;
            overflow: hidden;
        }

        .vad-bar {
            height: 100%;
            background: linear-gradient(90deg, #10b981 0%, #3b82f6 50%, #f59e0b 100%);
            width: 0%;
            transition: width 0.1s ease;
        }

        .conversation-log {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            height: 400px;
            overflow-y: auto;
            margin-bottom: 20px;
        }

        .message {
            margin-bottom: 15px;
            padding: 12px;
            border-radius: 8px;
            animation: slideIn 0.3s ease;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .message.user {
            background: #e0e7ff;
            border-left: 4px solid #667eea;
        }

        .message.agent {
            background: #d1fae5;
            border-left: 4px solid #10b981;
        }

        .message.system {
            background: #fef3c7;
            border-left: 4px solid #f59e0b;
            text-align: center;
            font-style: italic;
        }

        .message-label {
            font-weight: 600;
            font-size: 0.85em;
            margin-bottom: 5px;
            color: #555;
        }

        .message-text {
            color: #333;
            line-height: 1.5;
        }

        .info-box {
            background: #e0e7ff;
            border-radius: 8px;
            padding: 15px;
            margin-top: 20px;
            border-left: 4px solid #667eea;
        }

        .info-box h3 {
            margin-bottom: 10px;
            color: #333;
        }

        .info-box ul {
            margin-left: 20px;
            color: #555;
        }

        .info-box li {
            margin-bottom: 5px;
        }

        .loading {
            display: inline-block;
            width: 12px;
            height: 12px;
            border: 2px solid #667eea;
            border-radius: 50%;
            border-top-color: transparent;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        /* Current topic banner */
        .topic-banner {
            display: none;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 10px;
            padding: 14px 20px;
            margin-bottom: 20px;
            position: relative;
            overflow: hidden;
        }
        .topic-banner.visible { display: block; }
        .topic-banner .topic-label {
            font-size: 0.75em;
            text-transform: uppercase;
            letter-spacing: 1px;
            opacity: 0.85;
            margin-bottom: 4px;
        }
        .topic-banner .topic-module {
            font-size: 1.1em;
            font-weight: 700;
        }
        .topic-banner .topic-sub {
            font-size: 0.95em;
            font-weight: 400;
            opacity: 0.9;
        }
        .topic-banner .topic-progress {
            position: absolute;
            right: 20px;
            top: 50%;
            transform: translateY(-50%);
            background: rgba(255,255,255,0.2);
            border-radius: 6px;
            padding: 4px 12px;
            font-size: 0.8em;
            font-weight: 600;
        }

        /* Topic change notification in conversation log */
        .message.topic-change {
            background: linear-gradient(135deg, #e0e7ff 0%, #ede9fe 100%);
            border-left: 4px solid #764ba2;
            text-align: center;
            padding: 16px;
        }
        .message.topic-change .tc-icon { font-size: 1.5em; }
        .message.topic-change .tc-title { font-weight: 700; color: #4c1d95; margin: 4px 0; }
        .message.topic-change .tc-sub { color: #6d28d9; }

        .message.course-done {
            background: linear-gradient(135deg, #d1fae5 0%, #fef3c7 100%);
            border-left: 4px solid #10b981;
            text-align: center;
            padding: 20px;
        }
        .message.course-done .cd-icon { font-size: 2em; }
        .message.course-done .cd-text { font-weight: 700; color: #065f46; margin-top: 6px; }

        /* Thinking indicator */
        .message.thinking {
            background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%);
            border-left: 4px solid #f59e0b;
            text-align: center;
            padding: 12px;
        }
        .thinking-dots {
            display: inline-block;
        }
        .thinking-dots span {
            display: inline-block;
            width: 8px;
            height: 8px;
            margin: 0 3px;
            background: #f59e0b;
            border-radius: 50%;
            animation: bounce 1.4s infinite ease-in-out both;
        }
        .thinking-dots span:nth-child(1) { animation-delay: -0.32s; }
        .thinking-dots span:nth-child(2) { animation-delay: -0.16s; }
        @keyframes bounce {
            0%, 80%, 100% { transform: scale(0); }
            40% { transform: scale(1); }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéì Prof_AI Interactive Teaching</h1>
        <p class="subtitle">Two-way voice conversation with intelligent interruption support</p>

        <div class="status-card">
            <div class="status-row">
                <span class="status-label">Connection:</span>
                <span class="status-value">
                    <span class="status-indicator disconnected" id="connectionIndicator"></span>
                    <span id="connectionStatus">Disconnected</span>
                </span>
            </div>
            <div class="status-row">
                <span class="status-label">Microphone:</span>
                <span class="status-value">
                    <span class="status-indicator" id="micIndicator"></span>
                    <span id="micStatus">Inactive</span>
                </span>
            </div>
            <div class="status-row">
                <span class="status-label">Teaching State:</span>
                <span class="status-value" id="teachingState">Idle</span>
            </div>
        </div>

        <!-- Current topic banner (shown during teaching) -->
        <div class="topic-banner" id="topicBanner">
            <div class="topic-label">üìñ Currently Teaching</div>
            <div class="topic-module" id="topicModuleTitle">‚Äî</div>
            <div class="topic-sub" id="topicSubTitle">‚Äî</div>
            <div class="topic-progress" id="topicProgress"></div>
        </div>

        <div class="course-selector">
            <label>Course ID:</label>
            <input type="number" id="courseId" value="1" min="1">
            
            <label>Module Index:</label>
            <input type="number" id="moduleIndex" value="0" min="0" title="0-indexed module number">
            
            <label>Sub-topic Index:</label>
            <input type="number" id="subTopicIndex" value="0" min="0" title="0-indexed sub-topic number">
            
            <label>User ID:</label>
            <input type="text" id="userId" value="167" placeholder="Enter your user ID">

            <label>Language:</label>
            <select id="language">
                <option value="en-IN" selected>English (India)</option>
                <option value="hi-IN">Hindi</option>
                <option value="ta-IN">Tamil</option>
                <option value="te-IN">Telugu</option>
                <option value="bn-IN">Bengali</option>
                <option value="gu-IN">Gujarati</option>
                <option value="kn-IN">Kannada</option>
                <option value="ml-IN">Malayalam</option>
                <option value="mr-IN">Marathi</option>
                <option value="pa-IN">Punjabi</option>
            </select>
        </div>

        <div class="controls">
            <button class="btn-start" id="startBtn" onclick="startTeaching()">
                üéôÔ∏è Start Interactive Teaching
            </button>
            <button class="btn-continue" id="continueBtn" onclick="continueTeaching()" disabled>
                ‚ñ∂Ô∏è Continue Lesson
            </button>
            <button class="btn-end" id="endBtn" onclick="endTeaching()" disabled>
                ‚èπÔ∏è End Teaching
            </button>
        </div>

        <div class="vad-indicator">
            <div class="vad-label">Voice Activity: <span id="vadStatus">Idle</span></div>
            <div class="vad-bar-container">
                <div class="vad-bar" id="vadBar"></div>
            </div>
        </div>

        <!-- Real-time Latency Metrics -->
        <div id="latencyPanel" class="status-card" style="display:none; border-left-color: #10b981;">
            <div style="font-weight: 700; margin-bottom: 10px; color: #333;">üìä Real-Time Metrics</div>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 10px;">
                <div style="text-align: center;">
                    <div id="metricAnswerSource" style="font-size: 1.2em; font-weight: 700; color: #667eea;">-</div>
                    <div style="font-size: 0.75em; color: #888; text-transform: uppercase;">Answer Source</div>
                </div>
                <div style="text-align: center;">
                    <div id="metricBargeIn" style="font-size: 1.2em; font-weight: 700; color: #f59e0b;">-</div>
                    <div style="font-size: 0.75em; color: #888; text-transform: uppercase;">Barge-In (ms)</div>
                </div>
                <div style="text-align: center;">
                    <div id="metricAnswerTime" style="font-size: 1.2em; font-weight: 700; color: #10b981;">-</div>
                    <div style="font-size: 0.75em; color: #888; text-transform: uppercase;">Answer Gen (ms)</div>
                </div>
                <div style="text-align: center;">
                    <div id="metricFirstAudio" style="font-size: 1.2em; font-weight: 700; color: #3b82f6;">-</div>
                    <div style="font-size: 0.75em; color: #888; text-transform: uppercase;">First Audio (ms)</div>
                </div>
                <div style="text-align: center;">
                    <div id="metricTotalChunks" style="font-size: 1.2em; font-weight: 700; color: #8b5cf6;">0</div>
                    <div style="font-size: 0.75em; color: #888; text-transform: uppercase;">Audio Chunks</div>
                </div>
            </div>
        </div>

        <div class="conversation-log" id="conversationLog">
            <div class="message system">
                <div class="message-text">
                    Click "Start Interactive Teaching" to begin. You can interrupt and ask questions anytime during the lesson!
                </div>
            </div>
        </div>

        <div class="info-box">
            <h3>üí° How to Use:</h3>
            <ul>
                <li>üé§ <strong>Speak naturally</strong> - The system will detect your voice automatically</li>
                <li>üõë <strong>Interrupt anytime</strong> - Just start speaking to pause the lesson</li>
                <li>‚ùì <strong>Ask questions</strong> - Your questions will be answered in context</li>
                <li>‚ñ∂Ô∏è <strong>Continue</strong> - Click continue or wait for the lesson to resume</li>
            </ul>
        </div>
    </div>

    <script>
        // Configuration
        const WS_URL = 'ws://localhost:8765';

        // State
        let websocket = null;
        let audioContext = null;
        let mediaStream = null;
        let processor = null;
        let isConnected = false;
        let isSpeaking = false;
        let isTeaching = false;
        let isAgentSpeaking = false;
        let audioQueue = [];
        let isPlayingAudio = false;
        let currentAudio = null;  // Track currently playing audio
        let bargeInTimestamp = null;  // Track barge-in timing for metrics
        let lastPartialUpdate = 0;  // Throttle partial transcript updates
        let answerStartTime = null;  // Track when question was sent for answer gen timing
        let totalChunkCount = 0;    // Total audio chunks received
        let firstAnswerAudioTime = null; // Track first audio chunk after a question
        let audioPlaybackGen = 0;  // Incremented by stopAllAudio to abort playback loops

        // DOM Elements
        const startBtn = document.getElementById('startBtn');
        const continueBtn = document.getElementById('continueBtn');
        const endBtn = document.getElementById('endBtn');
        const connectionStatus = document.getElementById('connectionStatus');
        const connectionIndicator = document.getElementById('connectionIndicator');
        const micStatus = document.getElementById('micStatus');
        const micIndicator = document.getElementById('micIndicator');
        const teachingState = document.getElementById('teachingState');
        const vadStatus = document.getElementById('vadStatus');
        const vadBar = document.getElementById('vadBar');
        const conversationLog = document.getElementById('conversationLog');

        // Stop all audio playback and clear the queue
        function stopAllAudio() {
            audioPlaybackGen++;  // abort any running playAudioQueue loop
            if (currentAudio) {
                currentAudio.pause();  // triggers onpause ‚Üí resolves playPrepared Promise
                // playPrepared's done() sets currentAudio = null
            }
            audioQueue = [];
            isPlayingAudio = false;
            isAgentSpeaking = false;
        }

        // Update status indicators
        function updateStatus(connection, mic, teaching) {
            if (connection !== undefined) {
                connectionStatus.textContent = connection;
                connectionIndicator.className = 'status-indicator ' + 
                    (connection === 'Connected' ? 'connected' : 'disconnected');
            }
            if (mic !== undefined) {
                micStatus.textContent = mic;
                micIndicator.className = 'status-indicator ' + 
                    (mic === 'Speaking' ? 'speaking' : mic === 'Listening' ? 'listening' : '');
            }
            if (teaching !== undefined) {
                teachingState.textContent = teaching;
            }
        }

        // Add message to conversation log
        function addMessage(role, text) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;
            
            if (role === 'system') {
                messageDiv.innerHTML = `<div class="message-text">${text}</div>`;
            } else {
                messageDiv.innerHTML = `
                    <div class="message-label">${role === 'agent' ? 'ü§ñ Professor' : 'üë§ You'}</div>
                    <div class="message-text">${text}</div>
                `;
            }
            
            conversationLog.appendChild(messageDiv);
            conversationLog.scrollTop = conversationLog.scrollHeight;
        }

        // Start teaching session
        async function startTeaching() {
            try {
                startBtn.disabled = true;
                startBtn.innerHTML = '<span class="loading"></span> Connecting...';

                // Connect to WebSocket
                websocket = new WebSocket(WS_URL);

                websocket.onopen = async () => {
                    updateStatus('Connected', undefined, 'Initializing');
                    console.log('‚úÖ WebSocket connected');

                    // Request microphone access
                    try {
                        mediaStream = await navigator.mediaDevices.getUserMedia({
                            audio: {
                                sampleRate: 16000,
                                channelCount: 1,
                                echoCancellation: true,
                                noiseSuppression: true,
                                autoGainControl: true
                            }
                        });

                        console.log('‚úÖ Microphone access granted');

                        // Start audio processing
                        await startAudioProcessing();

                        // Send interactive teaching request
                        const teachingRequest = {
                            type: 'interactive_teaching',
                            course_id: parseInt(document.getElementById('courseId').value),
                            module_index: parseInt(document.getElementById('moduleIndex').value),
                            sub_topic_index: parseInt(document.getElementById('subTopicIndex').value),
                            user_id: document.getElementById('userId').value,
                            language: document.getElementById('language').value
                        };

                        console.log('üì§ Sending teaching request:', teachingRequest);
                        websocket.send(JSON.stringify(teachingRequest));

                        updateStatus('Connected', 'Listening', 'Starting');
                        startBtn.innerHTML = '‚úì Connected';
                        endBtn.disabled = false;
                        isConnected = true;
                        isTeaching = true;

                    } catch (error) {
                        console.error('‚ùå Microphone access denied:', error);
                        addMessage('system', '‚ö†Ô∏è Microphone access denied. Please allow microphone access.');
                        websocket.close();
                    }
                };

                websocket.onmessage = handleServerMessage;

                websocket.onerror = (error) => {
                    console.error('‚ùå WebSocket error:', error);
                    updateStatus('Error', 'Inactive', 'Error');
                };

                websocket.onclose = () => {
                    console.log('üîå WebSocket closed');
                    updateStatus('Disconnected', 'Inactive', 'Idle');
                    startBtn.disabled = false;
                    startBtn.innerHTML = 'üéôÔ∏è Start Interactive Teaching';
                    continueBtn.disabled = true;
                    endBtn.disabled = true;
                    isConnected = false;
                    isTeaching = false;

                    if (mediaStream) {
                        mediaStream.getTracks().forEach(track => track.stop());
                    }
                    if (audioContext) {
                        audioContext.close();
                    }
                };

            } catch (error) {
                console.error('‚ùå Connection error:', error);
                addMessage('system', `‚ùå Failed to connect: ${error.message}`);
                startBtn.disabled = false;
                startBtn.innerHTML = 'üéôÔ∏è Start Interactive Teaching';
            }
        }

        // Start audio processing ‚Äî simple continuous streaming like reference impl
        // Browser echoCancellation + noiseSuppression handles feedback/noise
        // Deepgram server-side VAD handles speech detection + endpointing
        async function startAudioProcessing() {
            audioContext = new AudioContext({ sampleRate: 16000 });
            const source = audioContext.createMediaStreamSource(mediaStream);
            processor = audioContext.createScriptProcessor(1024, 1, 1);

            processor.onaudioprocess = (e) => {
                const inputData = e.inputBuffer.getChannelData(0);

                // Calculate RMS for visual VAD indicator only
                let sum = 0;
                for (let i = 0; i < inputData.length; i++) {
                    sum += inputData[i] * inputData[i];
                }
                const rms = Math.sqrt(sum / inputData.length);

                // Visual VAD indicator + client-side barge-in
                const level = Math.min(100, rms * 500);
                vadBar.style.width = level + '%';
                if (rms > 0.02) {
                    vadStatus.textContent = 'SPEAKING';
                    if (!isSpeaking) {
                        isSpeaking = true;
                        // ‚îÄ‚îÄ Client-side barge-in: stop audio IMMEDIATELY ‚îÄ‚îÄ
                        // Don't wait for server's user_interrupt_detected ‚Äî
                        // the user needs instant silence + visual feedback.
                        if (isAgentSpeaking) {
                            console.log('üó£Ô∏è Client VAD: user speaking ‚Üí stopping audio');
                            stopAllAudio();
                            updateStatus(undefined, 'Speaking', 'Listening');
                            vadStatus.textContent = 'SPEAKING ‚Äî listening to you...';
                        }
                    }
                } else if (isSpeaking && rms < 0.01) {
                    vadStatus.textContent = 'Listening';
                    isSpeaking = false;
                }

                // ALWAYS send audio to Deepgram ‚Äî continuously, like reference impl
                // Browser echoCancellation handles TTS feedback
                // Deepgram handles VAD + endpointing (600ms silence ‚Üí final transcript)
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    const pcm16 = float32ToPCM16(inputData);
                    const audioBase64 = btoa(String.fromCharCode.apply(null, new Uint8Array(pcm16.buffer)));
                    websocket.send(JSON.stringify({
                        type: 'stt_audio_chunk',
                        audio: audioBase64
                    }));
                }
            };

            source.connect(processor);
            processor.connect(audioContext.destination);
            vadStatus.textContent = 'Listening';
            console.log('‚úÖ Audio processing started (continuous streaming)');
        }

        // Convert Float32 to PCM16
        function float32ToPCM16(float32Array) {
            const pcm16 = new Int16Array(float32Array.length);
            for (let i = 0; i < float32Array.length; i++) {
                const s = Math.max(-1, Math.min(1, float32Array[i]));
                pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return pcm16;
        }

        // Answer source helpers for hybrid architecture display
        function getSourceBadge(source) {
            const badges = {
                'langgraph_pedagogical': '<span style="background:#667eea;color:white;padding:2px 8px;border-radius:4px;font-size:0.75em;font-weight:600;">LangGraph</span>',
                'rag': '<span style="background:#10b981;color:white;padding:2px 8px;border-radius:4px;font-size:0.75em;font-weight:600;">RAG</span>',
                'general_llm': '<span style="background:#f59e0b;color:white;padding:2px 8px;border-radius:4px;font-size:0.75em;font-weight:600;">LLM</span>',
                'fallback': '<span style="background:#ef4444;color:white;padding:2px 8px;border-radius:4px;font-size:0.75em;font-weight:600;">Fallback</span>',
            };
            return badges[source] || '';
        }

        function getSourceLabel(source) {
            const labels = {
                'langgraph_pedagogical': 'LangGraph',
                'rag': 'RAG',
                'general_llm': 'LLM',
                'fallback': 'Fallback',
            };
            return labels[source] || source;
        }

        // Handle messages from server
        async function handleServerMessage(event) {
            try {
                const data = JSON.parse(event.data);
                console.log('üì® Received:', data.type);

                switch(data.type) {
                    case 'connection_ready':
                        console.log('‚úÖ Connection ready:', data.message);
                        break;

                    case 'interactive_teaching_init':
                        addMessage('system', 'üìö Loading course content...');
                        break;

                    case 'interactive_teaching_started':
                        addMessage('system', `‚úÖ Teaching Started: ${data.module_title} ‚Üí ${data.sub_topic_title}`);
                        // Show & populate topic banner
                        {
                            const banner = document.getElementById('topicBanner');
                            banner.classList.add('visible');
                            document.getElementById('topicModuleTitle').textContent = data.module_title || '';
                            document.getElementById('topicSubTitle').textContent = data.sub_topic_title || '';
                            document.getElementById('topicProgress').textContent =
                                `Module ${(parseInt(document.getElementById('moduleIndex').value) || 0) + 1} ¬∑ Topic ${(parseInt(document.getElementById('subTopicIndex').value) || 0) + 1}`;
                        }
                        updateStatus(undefined, 'Listening', 'Teaching Active');
                        document.getElementById('latencyPanel').style.display = 'block';
                        totalChunkCount = 0;
                        break;

                    case 'teaching_audio_chunk':
                        // Queue audio chunk for playback
                        audioQueue.push(data.audio_data);
                        if (!isPlayingAudio) {
                            playAudioQueue();
                        }
                        isAgentSpeaking = true;
                        totalChunkCount++;
                        document.getElementById('metricTotalChunks').textContent = totalChunkCount;
                        updateStatus(undefined, 'Listening', 'Professor Speaking');
                        break;

                    case 'teaching_segment_complete':
                        addMessage('system', '‚úÖ Section complete. You can ask questions or continue.');
                        continueBtn.disabled = false;
                        isAgentSpeaking = false;
                        updateStatus(undefined, 'Listening', 'Waiting');
                        break;

                    case 'user_interrupt_detected':
                        console.log('üõë User interrupt - stopping audio playback');
                        stopAllAudio();
                        
                        // Track barge-in timing
                        if (bargeInTimestamp) {
                            const bargeInMs = Date.now() - bargeInTimestamp;
                            document.getElementById('metricBargeIn').textContent = bargeInMs;
                            console.log(`‚è±Ô∏è Server barge-in ack: ${bargeInMs}ms after client detection`);
                        }
                        
                        addMessage('system', 'üëÇ Listening to your question...');
                        updateStatus(undefined, 'Speaking', 'Listening');
                        break;

                    case 'thinking_acknowledgment':
                        // Flush any remaining audio from the teaching stream
                        stopAllAudio();
                        // Show thinking indicator
                        {
                            // Remove any previous thinking message
                            const prev = document.getElementById('thinkingMsg');
                            if (prev) prev.remove();
                            const div = document.createElement('div');
                            div.className = 'message thinking';
                            div.id = 'thinkingMsg';
                            div.innerHTML = `
                                <div class="message-text">
                                    ü§î <strong>${data.message || 'Let me think about that...'}</strong>
                                    <div class="thinking-dots"><span></span><span></span><span></span></div>
                                </div>
                            `;
                            conversationLog.appendChild(div);
                            conversationLog.scrollTop = conversationLog.scrollHeight;
                        }
                        updateStatus(undefined, 'Listening', 'Thinking...');
                        break;

                    case 'partial_transcript':
                        // Throttle partial updates to avoid spam (max once per 500ms)
                        const now = Date.now();
                        if (now - lastPartialUpdate > 500) {
                            vadStatus.textContent = `"${data.text}"...`;
                            lastPartialUpdate = now;
                        }
                        break;

                    case 'user_question':
                        addMessage('user', data.text);
                        answerStartTime = Date.now();
                        firstAnswerAudioTime = null;
                        updateStatus(undefined, 'Listening', 'Processing');
                        break;

                    case 'agent_response':
                        // Remove thinking indicator if present
                        { const tm = document.getElementById('thinkingMsg'); if (tm) tm.remove(); }
                        // Hybrid architecture: shows answer source (langgraph_pedagogical / rag / general_llm)
                        const source = data.agent || data.source || 'unknown';
                        const sourceBadge = getSourceBadge(source);
                        addMessage('agent', `${sourceBadge} ${data.text}`);
                        document.getElementById('metricAnswerSource').textContent = getSourceLabel(source);
                        if (answerStartTime) {
                            const answerMs = Date.now() - answerStartTime;
                            document.getElementById('metricAnswerTime').textContent = answerMs;
                        }
                        updateStatus(undefined, 'Listening', 'Answering');
                        break;

                    case 'teaching_question_answer':
                        addMessage('agent', data.text);
                        if (answerStartTime) {
                            const qaMs = Date.now() - answerStartTime;
                            document.getElementById('metricAnswerTime').textContent = qaMs;
                        }
                        updateStatus(undefined, 'Listening', 'Answering');
                        break;

                    case 'answer_audio_chunk':
                        audioQueue.push(data.audio_data);
                        if (!isPlayingAudio) {
                            playAudioQueue();
                        }
                        isAgentSpeaking = true;
                        totalChunkCount++;
                        document.getElementById('metricTotalChunks').textContent = totalChunkCount;
                        // Track first audio after question
                        if (!firstAnswerAudioTime && answerStartTime) {
                            firstAnswerAudioTime = Date.now() - answerStartTime;
                            document.getElementById('metricFirstAudio').textContent = firstAnswerAudioTime;
                            console.log(`‚è±Ô∏è First answer audio: ${firstAnswerAudioTime}ms`);
                        }
                        break;

                    case 'answer_audio_complete':
                        if (data.duration_ms) {
                            console.log(`‚úÖ Answer audio complete: ${data.chunk_count} chunks in ${Math.round(data.duration_ms)}ms`);
                        }
                        break;

                    case 'answer_complete':
                        addMessage('system', data.message);
                        continueBtn.disabled = false;
                        isAgentSpeaking = false;
                        answerStartTime = null;
                        updateStatus(undefined, 'Listening', 'Waiting');
                        break;

                    case 'topic_advanced':
                        // Update topic banner
                        document.getElementById('topicModuleTitle').textContent = data.module_title || '';
                        document.getElementById('topicSubTitle').textContent = data.sub_topic_title || '';
                        document.getElementById('topicProgress').textContent =
                            `Module ${(data.module_index || 0) + 1} ¬∑ Topic ${(data.sub_topic_index || 0) + 1}`;
                        // Update input fields to reflect new position
                        document.getElementById('moduleIndex').value = data.module_index ?? 0;
                        document.getElementById('subTopicIndex').value = data.sub_topic_index ?? 0;
                        // Add styled notification in conversation log
                        {
                            const div = document.createElement('div');
                            div.className = 'message topic-change';
                            div.innerHTML = `
                                <div class="tc-icon">‚è≠Ô∏è</div>
                                <div class="tc-title">${data.module_title || 'Next Module'}</div>
                                <div class="tc-sub">${data.sub_topic_title || 'Next Topic'}</div>
                            `;
                            conversationLog.appendChild(div);
                            conversationLog.scrollTop = conversationLog.scrollHeight;
                        }
                        continueBtn.disabled = true;
                        updateStatus(undefined, 'Listening', 'Teaching Active');
                        break;

                    case 'course_complete':
                        {
                            const div = document.createElement('div');
                            div.className = 'message course-done';
                            div.innerHTML = `
                                <div class="cd-icon">üéâüéì</div>
                                <div class="cd-text">${data.message || 'Congratulations! Course complete!'}</div>
                            `;
                            conversationLog.appendChild(div);
                            conversationLog.scrollTop = conversationLog.scrollHeight;
                        }
                        document.getElementById('topicBanner').classList.remove('visible');
                        continueBtn.disabled = true;
                        updateStatus(undefined, 'Listening', 'Course Complete');
                        break;

                    case 'teaching_interrupted':
                    case 'teaching_cancelled':
                        console.log('üõë Teaching audio stopped');
                        break;

                    case 'teaching_resumed':
                        addMessage('system', '‚ñ∂Ô∏è Continuing the lesson...');
                        continueBtn.disabled = true;
                        updateStatus(undefined, 'Listening', 'Teaching Active');
                        break;

                    case 'teaching_paused':
                        addMessage('system', '‚è∏Ô∏è Lesson paused. Say "continue" or click Continue to resume.');
                        continueBtn.disabled = false;
                        updateStatus(undefined, 'Listening', 'Paused');
                        break;

                    case 'teaching_repeat':
                        addMessage('system', 'üîÑ Repeating the current section...');
                        updateStatus(undefined, 'Listening', 'Repeating');
                        break;

                    case 'teaching_ended':
                        addMessage('system', data.message || '‚úÖ Teaching session ended');
                        updateStatus(undefined, 'Inactive', 'Ended');
                        startBtn.disabled = false;
                        startBtn.innerHTML = 'üéôÔ∏è Start Interactive Teaching';
                        endBtn.disabled = true;
                        continueBtn.disabled = true;
                        isTeaching = false;
                        break;

                    case 'stt_unavailable':
                        addMessage('system', `‚ö†Ô∏è ${data.message}`);
                        break;

                    case 'error':
                        addMessage('system', `‚ùå Error: ${data.error}`);
                        console.error('Server error:', data.error);
                        break;

                    default:
                        console.log('Unknown message type:', data.type);
                }
            } catch (error) {
                console.error('‚ùå Error parsing message:', error);
            }
        }

        // ‚îÄ‚îÄ Seamless audio playback with pre-buffering ‚îÄ‚îÄ

        // Prepare (decode + preload) an Audio element from base64 WITHOUT playing it.
        // Returns { audio, url } ready to .play() instantly.
        function prepareAudio(audioBase64) {
            const raw = atob(audioBase64);
            const bytes = new Uint8Array(raw.length);
            for (let i = 0; i < raw.length; i++) bytes[i] = raw.charCodeAt(i);
            const blob = new Blob([bytes], { type: 'audio/mp3' });
            const url = URL.createObjectURL(blob);
            const audio = new Audio(url);
            audio.preload = 'auto';   // browser starts decoding immediately
            return { audio, url };
        }

        // Play a pre-built Audio element. Resolves on ended, pause, or abort
        // so that stopAllAudio() never leaves a dangling Promise.
        function playPrepared({ audio, url }) {
            return new Promise((resolve) => {
                let settled = false;
                const done = () => {
                    if (settled) return;
                    settled = true;
                    URL.revokeObjectURL(url);
                    if (currentAudio === audio) currentAudio = null;
                    resolve();
                };
                audio.onended  = done;
                audio.onpause  = done;   // ‚Üê stopAllAudio calls .pause()
                audio.onabort  = done;
                audio.onerror  = (e) => { console.warn('‚ö†Ô∏è chunk error', e); done(); };

                currentAudio = audio;
                audio.play().catch(done);   // autoplay-blocked ‚Üí skip gracefully
            });
        }

        // Main playback loop ‚Äî pre-buffers the NEXT chunk while the current
        // one is playing so there is virtually zero gap between chunks.
        async function playAudioQueue() {
            if (audioQueue.length === 0 || isPlayingAudio) return;
            isPlayingAudio = true;
            const myGen = audioPlaybackGen;

            let nextReady = null;   // pre-buffered { audio, url } for the next chunk

            while (audioPlaybackGen === myGen) {
                // Pick the chunk to play: either the pre-buffered one or decode now
                let toPlay = nextReady;
                nextReady = null;

                if (!toPlay) {
                    if (audioQueue.length === 0) break;
                    toPlay = prepareAudio(audioQueue.shift());
                }

                // While this chunk plays, pre-buffer the next one
                if (audioQueue.length > 0) {
                    nextReady = prepareAudio(audioQueue.shift());
                }

                try {
                    await playPrepared(toPlay);
                } catch (_) { /* already handled inside playPrepared */ }

                // If queue was empty and nothing pre-buffered, wait a tiny bit
                // for more chunks to arrive (streaming scenario)
                if (!nextReady && audioQueue.length === 0) {
                    await new Promise(r => setTimeout(r, 80));
                    if (audioQueue.length === 0) break;   // truly done
                }
            }

            // Cleanup pre-buffered chunk if we were interrupted
            if (nextReady) {
                URL.revokeObjectURL(nextReady.url);
                nextReady = null;
            }
            isPlayingAudio = false;
        }

        // Continue teaching
        function continueTeaching() {
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({ type: 'continue_teaching' }));
                continueBtn.disabled = true;
            }
        }

        // End teaching
        function endTeaching() {
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({ type: 'end_teaching' }));
            }
            if (websocket) {
                websocket.close();
            }
        }

        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            if (websocket) {
                websocket.close();
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
            }
        });
    </script>
</body>
</html>
